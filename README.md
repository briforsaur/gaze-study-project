# Eye Tracking and Pupillometry for Motor Intent Detection

**Lead researcher**: Dr. Shane Forbrigger, Department of Mechanical Engineering, 
Dalhousie University

**Other researchers**:

Prof. Ya-Jun Pan (supervisor), Department of Mechanical Engineering, Dalhousie 
University

Prof. Thomas Trappenberg, Department of Computer Science, Dalhousie University

**Funding**: We acknowledge the support of the Natural Sciences and Engineering Research 
Council of Canada (NSERC). Nous remercions le Conseil de recherches en sciences 
naturelles et en génie du Canada (CRSNG) de son soutien.

## Introduction
The purpose of this study is to learn about the differences between eye movements and 
changes in pupil size when picking up objects versus observing objects. We collected
gaze tracking and pupillometric data to train an algorithm to distinguish a person’s 
intended action (pick up or observe an object) based solely on their eye behaviour. This 
algorithm will serve as a proof-of-concept for an intuitive controller of assisted 
devices for people with arm motor impairments.

Participants in the study were asked to perform a series of simple tasks while their 
eyes and the scene in front of them, including their hands, were video-recorded. The 
recordings were captured using a Pupil Core headset (https://pupil-labs.com/products/core).
The tasks involved picking up dice from a table and reading numbers off those dice.

## Participation Criteria
Participants were allowed to participate in this study if they:
* were 18 years of age or older, and,
* had normal or corrected-to-normal vision (they could wear contact lenses, but 
eyeglasses would not fit with the eye tracking headset), sufficient to read the pips on
a die at arms length without squinting or straining.

Participation was disallowed if they:
* had neurological impairments that affected their ability to count, follow verbal 
instructions, or move their head or arms,
* had muscular impairments of the eyes, neck, trunk (torso), arm, or hand that would 
make it difficult or painful to move those body parts, or,
* could not hear auditory instructions.

## Methodology

## How to use
Navigate your terminal to the project root directory. I recommend creating a virtual
environment with `venv` or `conda` to keep the installed packages separate from your
main Python distrobution.

If you only want to work on the pupiltools package, install using `pip` in editable
mode:

```
python -m pip install -e .
```

If you want to run the scripts, you can install using the included `requirements.txt`
file:

```
python -m pip install -r requirements.txt
```

The package included with this project is named `pupiltools`. See the scripts in the
`/scripts` folder for examples of use.

### Building documentation
The documentation for the `pupiltools` package in this project is written to be 
compatible with [sphinx](https://www.sphinx-doc.org/en/master/) autodocumentation. To 
install the documentation requirements, either install using the `requirements.txt` 
file, or install the pupiltools package with the `docs` optional dependencies:

```
pip install -e .[docs]
```

You can build the documentation from the command line. With your virtual environment
active, enter the following command while in the project root directory:

```
sphinx-build ./docs/source/ ./docs/build
```

This publishes the html files in the `./docs/build` folder. You can change the build
destination folder to a different location if you prefer. If you open this folder
you will find an `index.html` file. Open this file in your browser to access the 
documentation.

If you make changes to the documentation you may need to do a full rebuild to make sure
that all tables of contents and other autogenerated content updates properly. Do do so,
run

```
sphinx-build -aE ./docs/source/ ./docs/build
```